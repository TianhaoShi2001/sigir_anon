{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df_origin = pd.read_pickle('./small_Books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_origin = pd.read_pickle('./small_meta_Books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = book_df_origin.copy()\n",
    "meta_df = meta_df_origin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_df.columns)\n",
    "print(book_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_title2id_dict = {}\n",
    "id_num = 0 # start from 0\n",
    "unique_titles = meta_df['title'].unique().tolist()\n",
    "for title in unique_titles:\n",
    "    original_title2id_dict[title] = id_num\n",
    "    id_num+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['title_idx'] = meta_df['title'].apply(lambda x:original_title2id_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. seperate cold-start and warm-start items according to item publish time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book_df.columns, meta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_meta_df = meta_df.copy()[['title','parent_asin','title_idx','publish_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_book_df = pd.merge(left = book_df, right=partial_meta_df,how = 'left',on='parent_asin', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_book_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_book_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['rating', 'iid', 'uid', 'timestamp', 'title', 'title_idx','publish_time']\n",
    "data['year'] = data['timestamp'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_publish_data = data[data['publish_time'] >= pd.to_datetime('2022-10-01')]\n",
    "cold_publish_items = cold_publish_data['title_idx'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_review_earliest_time = data.groupby('title_idx').agg({'timestamp':'min'})\n",
    "print(item_review_earliest_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_review_data = item_review_earliest_time[item_review_earliest_time['timestamp'] >= pd.to_datetime('2022-10-01')]\n",
    "cold_review_items = cold_review_data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_items = set(cold_review_items).intersection(set(cold_publish_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.get warm_train, warm_test, cold_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_start_time = '2016-01-01'\n",
    "cold_end_time = '2023-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_book_df.copy()\n",
    "data.columns = ['rating', 'iid', 'uid', 'timestamp', 'title', 'title_idx','publish_time']\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "data = data[(data['timestamp'] >= pd.to_datetime(warm_start_time)) & (data['timestamp'] <= pd.to_datetime(cold_end_time))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = data['timestamp'].dt.month + data['timestamp'].dt.year * 12\n",
    "data['month'] = data['month'] - data['month'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete cold data' interactions\n",
    "test_months = list(range(data['month'].max()-12+1,data['month'].max() +1 )) \n",
    "cold_data_test = cold_data[cold_data['month'].isin(test_months)]\n",
    "cold_items_test = cold_data_test['title_idx'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserve_warm_data = uncold_data\n",
    "cnt_warm = preserve_warm_data['iid'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process only warm_data\n",
    "preserve_warm_data_test = preserve_warm_data[preserve_warm_data['month'].isin(test_months)]\n",
    "preserve_warm_data_train = preserve_warm_data[~preserve_warm_data['month'].isin(test_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserve_warm_data_train['env'] = 0 # warm train\n",
    "preserve_warm_data_test['env'] = 1\n",
    "# the fake cold data denote items published before '2022-10-31',  \n",
    "# which means their text information may be collected in LLAMA-2's pretraining stage.\n",
    "# However, these items were not used in our final paper.\n",
    "# fake_cold_data_test['env'] = 2,fake_cold_data_test\n",
    "cold_data_test['env'] = 3\n",
    "all_data = pd.concat([preserve_warm_data_train,preserve_warm_data_test,cold_data_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users(all_data):\n",
    "    user_cnt = all_data['uid'].value_counts()\n",
    "    warm_users = user_cnt[user_cnt >= 20].index.tolist()\n",
    "    all_data = all_data[all_data['uid'].isin(warm_users)]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter items, preserve all items with interaction >= 20.\n",
    "def filer_items(all_data):\n",
    "    item_cnt = all_data['iid'].value_counts()\n",
    "    filer_items = item_cnt[item_cnt >= 20].index.tolist()\n",
    "    all_data = all_data[all_data['iid'].isin(filer_items)]\n",
    "    train_warm_cnt = all_data[all_data['env'] == 0]['iid'].value_counts()\n",
    "    delete_items = train_warm_cnt[train_warm_cnt < 20].index.unique().tolist()\n",
    "    all_data = all_data[~all_data['iid'].isin(delete_items)]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.shape[0])\n",
    "for i in range(5):\n",
    "    all_data = filter_users(all_data)\n",
    "    all_data = filer_items(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.shape[0])\n",
    "print(all_data[all_data['env'] == 0].shape[0]) # warm_train\n",
    "print(all_data[all_data['env'] == 1].shape[0]) # warm_test\n",
    "print(all_data[all_data['env'] == 3].shape[0]) # cold\n",
    "\n",
    "print(all_data[all_data['env'] == 0]['iid'].value_counts())\n",
    "print(all_data[all_data['env'] == 1]['iid'].value_counts())\n",
    "print(all_data[all_data['env'] == 3]['iid'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.save data for TALLRec and CF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_asin to iid\n",
    "parent_asin2iid_dict = {}\n",
    "num = 0\n",
    "for parent_asin in all_data['iid'].unique().tolist():\n",
    "    parent_asin2iid_dict[parent_asin] = num\n",
    "    num += 1\n",
    "all_data['iid'] = all_data['iid'].apply(lambda x: parent_asin2iid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(parent_asin2iid_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_asin to iid\n",
    "user_id2uid_dict = {}\n",
    "num = 0\n",
    "for user_id in all_data['uid'].unique().tolist():\n",
    "    user_id2uid_dict[user_id] = num\n",
    "    num += 1\n",
    "all_data['uid'] = all_data['uid'].apply(lambda x: user_id2uid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(user_id2uid_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data['publish_time'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.sort_values(by = 'timestamp', inplace=True, ascending=True)\n",
    "all_data['label'] = all_data['rating'].apply(lambda x: 1 if x>=4 else 0)\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "print(all_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_inter_all = all_data.groupby('uid').agg({'iid':list, 'label':list, 'title':list, 'timestamp':list, 'env':list})\n",
    "print(u_inter_all.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# get  [(seq0, label0), (seq1,label1)] for one user\n",
    "def deal_with_each_u(x,u):\n",
    "    items = np.array(x.iid)\n",
    "    labels = np.array(x.label)\n",
    "    titles = np.array(x.title)\n",
    "    timestamp = np.array(x.timestamp)\n",
    "    env = np.array(x.env)\n",
    "    his = [0] # adding a '0' by default\n",
    "    his_title = ['']\n",
    "    results = []\n",
    "    for i in range(items.shape[0]):\n",
    "        results.append((u, items[i], timestamp[i], np.array(his), copy.copy(his_title),titles[i], labels[i],env[i]))\n",
    "        # training data\n",
    "        if labels[i] > 0: # positive \n",
    "            his.append(items[i])\n",
    "            his_title.append(titles[i])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for u in u_inter_all.index:\n",
    "    results.extend(deal_with_each_u(u_inter_all.loc[u],u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_, i_, time_, label_, his_, his_title, title_,env_ = [],[],[],[],[],[],[],[]\n",
    "for re_ in results:\n",
    "    # if len(re_[3]) < 11:\n",
    "    #     continue\n",
    "    # else:\n",
    "        u_.append(re_[0])\n",
    "        i_.append(re_[1])\n",
    "        time_.append(re_[2])\n",
    "        his_.append(re_[3][-15:])\n",
    "        his_title.append(re_[4][-15:])\n",
    "        title_.append(re_[5])\n",
    "        label_.append(re_[6])\n",
    "        env_.append(re_[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame({\"uid\":u_,'iid':i_,'label':label_, 'timestamp': time_ , 'his':his_,'his_title':his_title,'title':title_,'env':env_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.shape)\n",
    "all_data.sort_values(by = 'timestamp', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[all_data['env'] == 0]\n",
    "warm_test = all_data[all_data['env'] == 1]\n",
    "cold_test = all_data[all_data['env'] == 3]\n",
    "print('warm train inter num', train_data.shape[0]) # warm_train\n",
    "print('warm evaluate inter num', warm_test.shape[0]) # warm_test\n",
    "print('cold evaluate inter num', cold_test.shape[0]) # cold (cold_test)\n",
    "mix_test = pd.concat((warm_test, cold_test))\n",
    "unique_iids = mix_test['iid'].unique().tolist()\n",
    "valid_data = []\n",
    "test_data = []\n",
    "for iid in unique_iids:\n",
    "    iid_data = mix_test.loc[mix_test['iid'] == iid]\n",
    "    split_index = len(iid_data) // 2  \n",
    "    valid_data.append(iid_data.iloc[:split_index])\n",
    "    test_data.append(iid_data.iloc[split_index:])\n",
    "valid_all = pd.concat(valid_data)\n",
    "test_all = pd.concat(test_data)\n",
    "warm_valid = valid_all[valid_all['env'] == 1]\n",
    "cold_valid = valid_all[valid_all['env'] == 3]\n",
    "warm_test = test_all[test_all['env'] == 1]\n",
    "cold_test = test_all[test_all['env'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('./train0.pkl')  # train_warm\n",
    "valid_all.to_pickle('./valid0.pkl') # valid_mix\n",
    "test_all.to_pickle('./test0.pkl') # valid_mix\n",
    "warm_valid.to_pickle('./valid1.pkl') # valid_warm\n",
    "cold_valid.to_pickle('./valid2.pkl') # valid_cold\n",
    "warm_test.to_pickle('./test1.pkl') # test_warm\n",
    "cold_test.to_pickle('./test2.pkl')  # test_cold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
